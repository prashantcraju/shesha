{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3vCfn1LdBmX4"
      },
      "source": [
        "# Shesha Tutorial: Training Drift Monitoring\n",
        "\n",
        "This notebook demonstrates how to use Shesha to monitor representation stability during model training.\n",
        "\n",
        "**What you'll learn:**\n",
        "- How to track geometric stability during training\n",
        "- How to detect representation collapse or divergence\n",
        "- How to balance stability vs task alignment\n",
        "\n",
        "**Requirements:**\n",
        "```bash\n",
        "pip install shesha-geometry torch\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GNJq5xCdBmX5"
      },
      "source": [
        "## 1. Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Optional: Install dependencies\n",
        "# !pip install shesha-geometry torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EJ9YC9jXBmX5"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import shesha\n",
        "\n",
        "SEED = 320\n",
        "np.random.seed(SEED)\n",
        "\n",
        "print(f\"Shesha version: {shesha.__version__}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QHsy5IyjBmX5"
      },
      "source": [
        "## 2. Simulate Training Dynamics\n",
        "\n",
        "We'll simulate different training scenarios to show how Shesha captures representation changes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X9HoAwD1BmX5"
      },
      "outputs": [],
      "source": [
        "def simulate_training(n_samples=500, n_features=256, n_epochs=20, scenario='healthy'):\n",
        "    \"\"\"\n",
        "    Simulate representation evolution during training.\n",
        "\n",
        "    Scenarios:\n",
        "    - 'healthy': Gradual improvement in task alignment while maintaining stability\n",
        "    - 'collapse': Representations collapse to low-dimensional manifold\n",
        "    - 'divergence': Representations become increasingly noisy\n",
        "    - 'overfit': Initial improvement followed by degradation\n",
        "    \"\"\"\n",
        "    rng = np.random.default_rng(SEED)\n",
        "\n",
        "    # Create labels (5 classes)\n",
        "    labels = np.repeat(np.arange(5), n_samples // 5)\n",
        "\n",
        "    # Base signal: low-rank structure\n",
        "    latent_dim = 30\n",
        "    latent = rng.standard_normal((n_samples, latent_dim))\n",
        "    projection = rng.standard_normal((latent_dim, n_features))\n",
        "    base_signal = latent @ projection\n",
        "    base_signal /= np.std(base_signal)\n",
        "\n",
        "    # Class centroids\n",
        "    class_directions = rng.standard_normal((5, n_features))\n",
        "    class_directions /= np.linalg.norm(class_directions, axis=1, keepdims=True)\n",
        "\n",
        "    embeddings_history = []\n",
        "\n",
        "    for epoch in range(n_epochs):\n",
        "        t = epoch / n_epochs\n",
        "\n",
        "        if scenario == 'healthy':\n",
        "            # Gradually add class signal while keeping structure\n",
        "            class_signal = np.array([class_directions[l] for l in labels]) * t * 2\n",
        "            noise = rng.standard_normal((n_samples, n_features)) * 0.3\n",
        "            embeddings = base_signal * (1 - 0.3*t) + class_signal + noise\n",
        "\n",
        "        elif scenario == 'collapse':\n",
        "            # Collapse to fewer dimensions over time\n",
        "            effective_dims = max(5, int(n_features * (1 - t * 0.9)))\n",
        "            embeddings = base_signal.copy()\n",
        "            embeddings[:, effective_dims:] *= (1 - t)\n",
        "\n",
        "        elif scenario == 'divergence':\n",
        "            # Increasing noise\n",
        "            noise_scale = 0.1 + t * 3\n",
        "            noise = rng.standard_normal((n_samples, n_features)) * noise_scale\n",
        "            embeddings = base_signal + noise\n",
        "\n",
        "        elif scenario == 'overfit':\n",
        "            # Good until midpoint, then degrade\n",
        "            if t < 0.5:\n",
        "                class_signal = np.array([class_directions[l] for l in labels]) * t * 4\n",
        "                noise = rng.standard_normal((n_samples, n_features)) * 0.2\n",
        "            else:\n",
        "                # Overfit: memorize training data, lose structure\n",
        "                class_signal = np.array([class_directions[l] for l in labels]) * 2\n",
        "                noise = rng.standard_normal((n_samples, n_features)) * (t - 0.3) * 2\n",
        "            embeddings = base_signal * (1 - t * 0.5) + class_signal + noise\n",
        "\n",
        "        embeddings_history.append(embeddings)\n",
        "\n",
        "    return embeddings_history, labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "updpiL_pBmX6"
      },
      "source": [
        "## 3. Monitor Training with Shesha"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O-memAjxBmX6"
      },
      "outputs": [],
      "source": [
        "def monitor_training(embeddings_history, labels):\n",
        "    \"\"\"Compute Shesha metrics at each epoch.\"\"\"\n",
        "    metrics = {'stability': [], 'alignment': [], 'var_ratio': []}\n",
        "\n",
        "    for embeddings in embeddings_history:\n",
        "        metrics['stability'].append(shesha.feature_split(embeddings, seed=SEED))\n",
        "        metrics['alignment'].append(shesha.supervised_alignment(embeddings, labels, seed=SEED))\n",
        "        metrics['var_ratio'].append(shesha.variance_ratio(embeddings, labels))\n",
        "\n",
        "    return metrics\n",
        "\n",
        "# Run all scenarios\n",
        "scenarios = ['healthy', 'collapse', 'divergence', 'overfit']\n",
        "all_metrics = {}\n",
        "\n",
        "for scenario in scenarios:\n",
        "    print(f\"Simulating {scenario} training...\")\n",
        "    history, labels = simulate_training(scenario=scenario)\n",
        "    all_metrics[scenario] = monitor_training(history, labels)\n",
        "\n",
        "print(\"Done!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ixQ1i4qRBmX6"
      },
      "source": [
        "## 4. Visualize Training Dynamics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kSRdpQv-BmX6"
      },
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
        "epochs = range(20)\n",
        "\n",
        "titles = {\n",
        "    'healthy': 'Healthy Training',\n",
        "    'collapse': 'Representation Collapse',\n",
        "    'divergence': 'Divergence (Noisy)',\n",
        "    'overfit': 'Overfitting'\n",
        "}\n",
        "\n",
        "for ax, scenario in zip(axes.flat, scenarios):\n",
        "    m = all_metrics[scenario]\n",
        "\n",
        "    ax.plot(epochs, m['stability'], 'b-o', label='Stability', markersize=4)\n",
        "    ax.plot(epochs, m['alignment'], 'r-s', label='Alignment', markersize=4)\n",
        "    ax.plot(epochs, m['var_ratio'], 'g-^', label='Var Ratio', markersize=4)\n",
        "\n",
        "    ax.set_xlabel('Epoch')\n",
        "    ax.set_ylabel('Score')\n",
        "    ax.set_title(titles[scenario])\n",
        "    ax.legend(loc='best', fontsize='small')\n",
        "    ax.grid(True, alpha=0.3)\n",
        "    ax.set_ylim(-0.1, 1.0)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('training_dynamics.png', dpi=150)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8zsnrW2GBmX6"
      },
      "source": [
        "## 5. Interpretation\n",
        "\n",
        "| Scenario | Stability | Alignment | Diagnosis |\n",
        "|----------|-----------|-----------|----------|\n",
        "| **Healthy** | Stable/slight decrease | Increases | Normal - learning task while maintaining structure |\n",
        "| **Collapse** | Drops sharply | Variable | Bad - representations losing information |\n",
        "| **Divergence** | Drops to ~0 | Drops to ~0 | Bad - signal overwhelmed by noise |\n",
        "| **Overfit** | Drops late | Peaks then drops | Warning - memorizing rather than generalizing |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AJO0l20QBmX6"
      },
      "source": [
        "## 6. Early Stopping with Shesha"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CWbh-CiNBmX6"
      },
      "outputs": [],
      "source": [
        "def should_stop_early(metrics, patience=3, stability_threshold=0.2):\n",
        "    \"\"\"\n",
        "    Simple early stopping based on stability.\n",
        "\n",
        "    Stop if stability drops below threshold for 'patience' epochs.\n",
        "    \"\"\"\n",
        "    recent = metrics['stability'][-patience:]\n",
        "    if len(recent) < patience:\n",
        "        return False\n",
        "    return all(s < stability_threshold for s in recent)\n",
        "\n",
        "# Demo\n",
        "print(\"Early stopping analysis:\")\n",
        "for scenario in scenarios:\n",
        "    m = all_metrics[scenario]\n",
        "    for epoch in range(5, 20):\n",
        "        partial = {k: v[:epoch] for k, v in m.items()}\n",
        "        if should_stop_early(partial):\n",
        "            print(f\"  {scenario}: Stop at epoch {epoch}\")\n",
        "            break\n",
        "    else:\n",
        "        print(f\"  {scenario}: No early stop triggered\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wL8kAzmhBmX6"
      },
      "source": [
        "## 7. Quick Reference\n",
        "\n",
        "```python\n",
        "import shesha\n",
        "\n",
        "# In your training loop:\n",
        "for epoch in range(n_epochs):\n",
        "    train_one_epoch(model, data)\n",
        "    \n",
        "    # Extract embeddings from validation set\n",
        "    embeddings = get_embeddings(model, val_data)\n",
        "    \n",
        "    # Monitor stability\n",
        "    stability = shesha.feature_split(embeddings, seed=320)\n",
        "    \n",
        "    # Log metrics\n",
        "    wandb.log({'stability': stability, 'epoch': epoch})\n",
        "    \n",
        "    # Early stopping check\n",
        "    if stability < 0.1:\n",
        "        print(\"Warning: Representation collapse detected!\")\n",
        "```\n",
        "\n",
        "**Red flags:**\n",
        "- Stability < 0.1: Possible collapse or noise\n",
        "- Sudden stability drop: Check for bugs or bad hyperparameters\n",
        "- Alignment drops while loss decreases: Overfitting"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
