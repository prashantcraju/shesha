{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1vZAkEQxPOGV"
      },
      "source": [
        "# Shesha Tutorial: Steering Vector Analysis\n",
        "\n",
        "This notebook demonstrates how to use Shesha to analyze the consistency of steering vectors in language models.\n",
        "\n",
        "**What you'll learn:**\n",
        "- How to compute steering vectors from contrastive pairs\n",
        "- How to apply steering vectors to a model\n",
        "- How to measure steering consistency with Shesha\n",
        "- How to evaluate steering effectiveness\n",
        "\n",
        "**Requirements:**\n",
        "```bash\n",
        "pip install shesha-geometry torch transformers datasets\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Whbj9hFtPOGW"
      },
      "source": [
        "## 1. Setup and Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Optional: Install dependencies\n",
        "# !pip install shesha-geometry torch transformers datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3r9cTcE-POGX"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import spearmanr\n",
        "\n",
        "import shesha\n",
        "from shesha.bio import perturbation_stability, perturbation_effect_size\n",
        "\n",
        "SEED = 320\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "\n",
        "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(f\"Device: {DEVICE}\")\n",
        "print(f\"Shesha version: {shesha.__version__}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fTRAHFDWPOGX"
      },
      "source": [
        "## 2. Load Model and Tokenizer\n",
        "\n",
        "We'll use GPT-2 small for this demo. The same approach works with any causal LM."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n7VyvBqkPOGY"
      },
      "outputs": [],
      "source": [
        "MODEL_NAME = \"gpt2\"\n",
        "\n",
        "print(f\"Loading {MODEL_NAME}...\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    MODEL_NAME,\n",
        "    output_hidden_states=True\n",
        ")\n",
        "model = model.to(DEVICE)\n",
        "model.eval()\n",
        "\n",
        "print(f\"Loaded: {model.config.n_layer} layers, {model.config.n_embd} hidden dim\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rHWhziRXPOGY"
      },
      "source": [
        "## 3. Define Contrastive Prompt Pairs\n",
        "\n",
        "Steering vectors are computed from pairs of prompts that differ in some attribute (e.g., sentiment, formality, toxicity)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EnTUFRC3POGY"
      },
      "outputs": [],
      "source": [
        "# Sentiment steering: positive vs negative\n",
        "positive_prompts = [\n",
        "    \"I feel absolutely wonderful today because\",\n",
        "    \"This is the best day of my life since\",\n",
        "    \"I am so happy and grateful that\",\n",
        "    \"Everything is going great and I love\",\n",
        "    \"I'm excited and optimistic about\",\n",
        "    \"This brings me so much joy because\",\n",
        "    \"I feel blessed and thankful for\",\n",
        "    \"What a fantastic experience when\",\n",
        "    \"I'm thrilled to announce that\",\n",
        "    \"Life is beautiful especially when\",\n",
        "    \"I absolutely love the way\",\n",
        "    \"This makes me incredibly happy since\",\n",
        "    \"I'm overjoyed to discover that\",\n",
        "    \"What wonderful news about\",\n",
        "    \"I feel so fortunate because\",\n",
        "]\n",
        "\n",
        "negative_prompts = [\n",
        "    \"I feel absolutely terrible today because\",\n",
        "    \"This is the worst day of my life since\",\n",
        "    \"I am so sad and disappointed that\",\n",
        "    \"Everything is going wrong and I hate\",\n",
        "    \"I'm worried and pessimistic about\",\n",
        "    \"This brings me so much pain because\",\n",
        "    \"I feel cursed and resentful for\",\n",
        "    \"What a horrible experience when\",\n",
        "    \"I'm devastated to announce that\",\n",
        "    \"Life is miserable especially when\",\n",
        "    \"I absolutely hate the way\",\n",
        "    \"This makes me incredibly sad since\",\n",
        "    \"I'm heartbroken to discover that\",\n",
        "    \"What terrible news about\",\n",
        "    \"I feel so unfortunate because\",\n",
        "]\n",
        "\n",
        "print(f\"Contrastive pairs: {len(positive_prompts)}\")\n",
        "print(f\"\\nExample pair:\")\n",
        "print(f\"  (+) {positive_prompts[0]}\")\n",
        "print(f\"  (-) {negative_prompts[0]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0sPo3HWGPOGZ"
      },
      "source": [
        "## 4. Extract Hidden States"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GJG4EyOhPOGZ"
      },
      "outputs": [],
      "source": [
        "def get_hidden_states(model, tokenizer, prompts, layer_idx=-1):\n",
        "    \"\"\"\n",
        "    Extract hidden states from a specific layer.\n",
        "\n",
        "    Args:\n",
        "        model: HuggingFace model with output_hidden_states=True\n",
        "        tokenizer: Corresponding tokenizer\n",
        "        prompts: List of text prompts\n",
        "        layer_idx: Which layer to extract (-1 = last layer)\n",
        "\n",
        "    Returns:\n",
        "        np.array of shape (n_prompts, hidden_dim)\n",
        "    \"\"\"\n",
        "    hidden_states = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for prompt in prompts:\n",
        "            inputs = tokenizer(prompt, return_tensors=\"pt\").to(DEVICE)\n",
        "            outputs = model(**inputs)\n",
        "\n",
        "            # Get hidden state at specified layer, last token position\n",
        "            # hidden_states tuple: (n_layers + 1, batch, seq_len, hidden_dim)\n",
        "            hs = outputs.hidden_states[layer_idx][0, -1, :].cpu().numpy()\n",
        "            hidden_states.append(hs)\n",
        "\n",
        "    return np.array(hidden_states)\n",
        "\n",
        "# Test extraction\n",
        "test_hs = get_hidden_states(model, tokenizer, [\"Hello world\"], layer_idx=-1)\n",
        "print(f\"Hidden state shape: {test_hs.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3JnOdt56POGZ"
      },
      "source": [
        "## 5. Compute Steering Vector\n",
        "\n",
        "The steering vector is the mean difference between positive and negative embeddings."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OF_hA3oFPOGZ"
      },
      "outputs": [],
      "source": [
        "def compute_steering_vector(model, tokenizer, positive_prompts, negative_prompts, layer_idx=-1):\n",
        "    \"\"\"\n",
        "    Compute steering vector as mean(positive) - mean(negative).\n",
        "\n",
        "    Returns:\n",
        "        steering_vector: np.array of shape (hidden_dim,)\n",
        "        positive_hs: Hidden states for positive prompts\n",
        "        negative_hs: Hidden states for negative prompts\n",
        "    \"\"\"\n",
        "    print(\"Extracting positive hidden states...\")\n",
        "    positive_hs = get_hidden_states(model, tokenizer, positive_prompts, layer_idx)\n",
        "\n",
        "    print(\"Extracting negative hidden states...\")\n",
        "    negative_hs = get_hidden_states(model, tokenizer, negative_prompts, layer_idx)\n",
        "\n",
        "    # Steering vector: direction from negative to positive\n",
        "    steering_vector = positive_hs.mean(axis=0) - negative_hs.mean(axis=0)\n",
        "\n",
        "    print(f\"Steering vector norm: {np.linalg.norm(steering_vector):.3f}\")\n",
        "\n",
        "    return steering_vector, positive_hs, negative_hs\n",
        "\n",
        "# Compute at layer 8 (middle layer often works well)\n",
        "TARGET_LAYER = 8\n",
        "steering_vector, pos_hs, neg_hs = compute_steering_vector(\n",
        "    model, tokenizer, positive_prompts, negative_prompts, layer_idx=TARGET_LAYER\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6dDdD6A2POGZ"
      },
      "source": [
        "## 6. Analyze Steering Consistency with Shesha\n",
        "\n",
        "Before applying the steering vector, let's check if the contrastive pairs give a consistent direction."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_7CPhrFnPOGZ"
      },
      "outputs": [],
      "source": [
        "# Compute per-pair steering vectors\n",
        "per_pair_vectors = pos_hs - neg_hs\n",
        "print(f\"Per-pair vectors shape: {per_pair_vectors.shape}\")\n",
        "\n",
        "# Method 1: Cosine similarity to mean direction\n",
        "mean_direction = steering_vector / np.linalg.norm(steering_vector)\n",
        "cosine_sims = []\n",
        "for v in per_pair_vectors:\n",
        "    v_norm = v / (np.linalg.norm(v) + 1e-8)\n",
        "    cosine_sims.append(np.dot(v_norm, mean_direction))\n",
        "\n",
        "print(f\"\\nCosine similarity to mean direction:\")\n",
        "print(f\"  Mean: {np.mean(cosine_sims):.3f}\")\n",
        "print(f\"  Std:  {np.std(cosine_sims):.3f}\")\n",
        "print(f\"  Min:  {np.min(cosine_sims):.3f}\")\n",
        "print(f\"  Max:  {np.max(cosine_sims):.3f}\")\n",
        "\n",
        "# Method 2: Use Shesha perturbation_stability\n",
        "# Treat negative as \"control\" and positive as \"perturbed\"\n",
        "stability = perturbation_stability(neg_hs, pos_hs, seed=SEED)\n",
        "effect = perturbation_effect_size(neg_hs, pos_hs)\n",
        "\n",
        "print(f\"\\nShesha Metrics:\")\n",
        "print(f\"  Stability:   {stability:.3f}\")\n",
        "print(f\"  Effect Size: {effect:.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MC9iN4iZPOGa"
      },
      "outputs": [],
      "source": [
        "# Visualize consistency\n",
        "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
        "\n",
        "# Plot 1: Cosine similarities histogram\n",
        "ax = axes[0]\n",
        "ax.hist(cosine_sims, bins=10, edgecolor='black', alpha=0.7)\n",
        "ax.axvline(np.mean(cosine_sims), color='red', linestyle='--', label=f'Mean: {np.mean(cosine_sims):.3f}')\n",
        "ax.set_xlabel('Cosine Similarity to Mean Direction')\n",
        "ax.set_ylabel('Count')\n",
        "ax.set_title('Steering Direction Consistency')\n",
        "ax.legend()\n",
        "ax.grid(True, alpha=0.3)\n",
        "\n",
        "# Plot 2: Per-pair vector magnitudes\n",
        "ax = axes[1]\n",
        "magnitudes = np.linalg.norm(per_pair_vectors, axis=1)\n",
        "ax.bar(range(len(magnitudes)), magnitudes, alpha=0.7)\n",
        "ax.axhline(np.mean(magnitudes), color='red', linestyle='--', label=f'Mean: {np.mean(magnitudes):.2f}')\n",
        "ax.set_xlabel('Prompt Pair Index')\n",
        "ax.set_ylabel('Steering Magnitude')\n",
        "ax.set_title('Per-Pair Steering Magnitude')\n",
        "ax.legend()\n",
        "ax.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('steering_consistency.png', dpi=150)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5GJuHdpJPOGa"
      },
      "source": [
        "## 7. Create Steered Model\n",
        "\n",
        "We'll create a hook that adds the steering vector to the residual stream."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TWOjnZP9POGa"
      },
      "outputs": [],
      "source": [
        "class SteeringHook:\n",
        "    \"\"\"Hook to add steering vector at a specific layer.\"\"\"\n",
        "\n",
        "    def __init__(self, steering_vector, scale=1.0):\n",
        "        self.steering_vector = torch.tensor(steering_vector, dtype=torch.float32)\n",
        "        self.scale = scale\n",
        "        self.handle = None\n",
        "\n",
        "    def __call__(self, module, input, output):\n",
        "        # output is (hidden_states, ...)\n",
        "        if isinstance(output, tuple):\n",
        "            hidden_states = output[0]\n",
        "        else:\n",
        "            hidden_states = output\n",
        "\n",
        "        # Add steering vector to all positions\n",
        "        sv = self.steering_vector.to(hidden_states.device)\n",
        "        hidden_states = hidden_states + self.scale * sv\n",
        "\n",
        "        if isinstance(output, tuple):\n",
        "            return (hidden_states,) + output[1:]\n",
        "        return hidden_states\n",
        "\n",
        "    def register(self, model, layer_idx):\n",
        "        \"\"\"Register hook on specified layer.\"\"\"\n",
        "        layer = model.transformer.h[layer_idx]\n",
        "        self.handle = layer.register_forward_hook(self)\n",
        "        return self\n",
        "\n",
        "    def remove(self):\n",
        "        \"\"\"Remove the hook.\"\"\"\n",
        "        if self.handle:\n",
        "            self.handle.remove()\n",
        "            self.handle = None\n",
        "\n",
        "print(\"SteeringHook defined.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WCJoHsAbPOGa"
      },
      "source": [
        "## 8. Test Steering Effect"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BSZURL6QPOGa"
      },
      "outputs": [],
      "source": [
        "def generate_text(model, tokenizer, prompt, max_new_tokens=30):\n",
        "    \"\"\"Generate text from a prompt.\"\"\"\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(DEVICE)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model.generate(\n",
        "            **inputs,\n",
        "            max_new_tokens=max_new_tokens,\n",
        "            do_sample=True,\n",
        "            temperature=0.7,\n",
        "            top_p=0.9,\n",
        "            pad_token_id=tokenizer.eos_token_id\n",
        "        )\n",
        "\n",
        "    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "# Test prompts (neutral)\n",
        "test_prompts = [\n",
        "    \"Today I went to the store and\",\n",
        "    \"The weather outside is\",\n",
        "    \"I think the future will be\",\n",
        "]\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"WITHOUT STEERING\")\n",
        "print(\"=\" * 60)\n",
        "for prompt in test_prompts:\n",
        "    output = generate_text(model, tokenizer, prompt)\n",
        "    print(f\"\\n{output}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O7dlHHfePOGa"
      },
      "outputs": [],
      "source": [
        "# Apply positive steering\n",
        "print(\"=\" * 60)\n",
        "print(\"WITH POSITIVE STEERING (scale=2.0)\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "hook = SteeringHook(steering_vector, scale=2.0)\n",
        "hook.register(model, TARGET_LAYER)\n",
        "\n",
        "for prompt in test_prompts:\n",
        "    output = generate_text(model, tokenizer, prompt)\n",
        "    print(f\"\\n{output}\")\n",
        "\n",
        "hook.remove()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4UI46dNKPOGa"
      },
      "outputs": [],
      "source": [
        "# Apply negative steering (flip the direction)\n",
        "print(\"=\" * 60)\n",
        "print(\"WITH NEGATIVE STEERING (scale=-2.0)\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "hook = SteeringHook(steering_vector, scale=-2.0)\n",
        "hook.register(model, TARGET_LAYER)\n",
        "\n",
        "for prompt in test_prompts:\n",
        "    output = generate_text(model, tokenizer, prompt)\n",
        "    print(f\"\\n{output}\")\n",
        "\n",
        "hook.remove()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7r8Q-LcOPOGa"
      },
      "source": [
        "## 9. Measure Steering Effect with Shesha\n",
        "\n",
        "Now let's quantitatively measure the steering effect on a larger set of prompts."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1R0LUo_RPOGb"
      },
      "outputs": [],
      "source": [
        "# Neutral evaluation prompts\n",
        "eval_prompts = [\n",
        "    \"I went to the park and\",\n",
        "    \"My friend told me that\",\n",
        "    \"The movie was about\",\n",
        "    \"I decided to try\",\n",
        "    \"The restaurant served\",\n",
        "    \"My coworker mentioned\",\n",
        "    \"I read a book about\",\n",
        "    \"The trip to the beach was\",\n",
        "    \"I learned something new about\",\n",
        "    \"The meeting went\",\n",
        "    \"I found out that\",\n",
        "    \"The coffee shop had\",\n",
        "    \"My neighbor said\",\n",
        "    \"The concert was\",\n",
        "    \"I thought about\",\n",
        "    \"The garden looked\",\n",
        "    \"My teacher explained\",\n",
        "    \"The sunset was\",\n",
        "    \"I remembered when\",\n",
        "    \"The museum had\",\n",
        "]\n",
        "\n",
        "print(f\"Evaluation prompts: {len(eval_prompts)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E_A_fd4cPOGb"
      },
      "outputs": [],
      "source": [
        "# Extract embeddings without steering\n",
        "print(\"Extracting baseline embeddings...\")\n",
        "X_baseline = get_hidden_states(model, tokenizer, eval_prompts, layer_idx=TARGET_LAYER)\n",
        "print(f\"Baseline shape: {X_baseline.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SxxdFaf5POGb"
      },
      "outputs": [],
      "source": [
        "# Extract embeddings with steering at different scales\n",
        "scales = [0.5, 1.0, 2.0, 3.0, 5.0]\n",
        "steered_embeddings = {}\n",
        "\n",
        "for scale in scales:\n",
        "    print(f\"Extracting with scale={scale}...\")\n",
        "    hook = SteeringHook(steering_vector, scale=scale)\n",
        "    hook.register(model, TARGET_LAYER)\n",
        "\n",
        "    X_steered = get_hidden_states(model, tokenizer, eval_prompts, layer_idx=-1)\n",
        "    steered_embeddings[scale] = X_steered\n",
        "\n",
        "    hook.remove()\n",
        "\n",
        "print(\"Done!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4-_vD8DQPOGb"
      },
      "outputs": [],
      "source": [
        "# Compute Shesha metrics for each scale\n",
        "results = []\n",
        "\n",
        "print(f\"{'Scale':<8} {'Stability':>10} {'Effect':>10}\")\n",
        "print(\"-\" * 30)\n",
        "\n",
        "for scale in scales:\n",
        "    X_steered = steered_embeddings[scale]\n",
        "\n",
        "    stability = perturbation_stability(X_baseline, X_steered, seed=SEED)\n",
        "    effect = perturbation_effect_size(X_baseline, X_steered)\n",
        "\n",
        "    results.append({\n",
        "        'scale': scale,\n",
        "        'stability': stability,\n",
        "        'effect_size': effect\n",
        "    })\n",
        "\n",
        "    print(f\"{scale:<8} {stability:>10.3f} {effect:>10.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jb4uECK4POGb"
      },
      "outputs": [],
      "source": [
        "# Visualize\n",
        "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
        "\n",
        "scales_arr = [r['scale'] for r in results]\n",
        "stabilities = [r['stability'] for r in results]\n",
        "effects = [r['effect_size'] for r in results]\n",
        "\n",
        "# Plot 1: Stability vs Scale\n",
        "ax = axes[0]\n",
        "ax.plot(scales_arr, stabilities, 'b-o', markersize=8)\n",
        "ax.set_xlabel('Steering Scale')\n",
        "ax.set_ylabel('Stability')\n",
        "ax.set_title('Steering Consistency vs Scale')\n",
        "ax.axhline(0.5, color='gray', linestyle='--', alpha=0.5)\n",
        "ax.grid(True, alpha=0.3)\n",
        "\n",
        "# Plot 2: Effect Size vs Scale\n",
        "ax = axes[1]\n",
        "ax.plot(scales_arr, effects, 'r-s', markersize=8)\n",
        "ax.set_xlabel('Steering Scale')\n",
        "ax.set_ylabel('Effect Size')\n",
        "ax.set_title('Steering Magnitude vs Scale')\n",
        "ax.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('steering_scaling.png', dpi=150)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wa7z5sBzPOGb"
      },
      "source": [
        "## 10. Compare Steering Across Layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zQDKEKOBPOGc"
      },
      "outputs": [],
      "source": [
        "# Compute steering vectors at different layers\n",
        "layer_results = []\n",
        "test_layers = [2, 4, 6, 8, 10]\n",
        "\n",
        "for layer_idx in test_layers:\n",
        "    print(f\"\\nAnalyzing layer {layer_idx}...\")\n",
        "\n",
        "    # Compute steering vector at this layer\n",
        "    sv, pos_hs, neg_hs = compute_steering_vector(\n",
        "        model, tokenizer, positive_prompts, negative_prompts, layer_idx=layer_idx\n",
        "    )\n",
        "\n",
        "    # Measure consistency of contrastive pairs\n",
        "    stability = perturbation_stability(neg_hs, pos_hs, seed=SEED)\n",
        "    effect = perturbation_effect_size(neg_hs, pos_hs)\n",
        "\n",
        "    layer_results.append({\n",
        "        'layer': layer_idx,\n",
        "        'stability': stability,\n",
        "        'effect_size': effect,\n",
        "        'sv_norm': np.linalg.norm(sv)\n",
        "    })\n",
        "\n",
        "print(f\"\\n{'Layer':<8} {'Stability':>10} {'Effect':>10} {'SV Norm':>10}\")\n",
        "print(\"-\" * 40)\n",
        "for r in layer_results:\n",
        "    print(f\"{r['layer']:<8} {r['stability']:>10.3f} {r['effect_size']:>10.2f} {r['sv_norm']:>10.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6-f1BLF2POGc"
      },
      "outputs": [],
      "source": [
        "# Visualize layer comparison\n",
        "fig, ax = plt.subplots(figsize=(8, 5))\n",
        "\n",
        "layers = [r['layer'] for r in layer_results]\n",
        "stabilities = [r['stability'] for r in layer_results]\n",
        "effects = [r['effect_size'] for r in layer_results]\n",
        "\n",
        "ax.plot(layers, stabilities, 'b-o', label='Stability', markersize=8)\n",
        "ax.plot(layers, [e/max(effects) for e in effects], 'r-s', label='Effect (normalized)', markersize=8)\n",
        "\n",
        "ax.set_xlabel('Layer')\n",
        "ax.set_ylabel('Score')\n",
        "ax.set_title('Steering Quality Across Layers')\n",
        "ax.legend()\n",
        "ax.grid(True, alpha=0.3)\n",
        "ax.set_xticks(layers)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('steering_layers.png', dpi=150)\n",
        "plt.show()\n",
        "\n",
        "# Find best layer\n",
        "best_layer = max(layer_results, key=lambda x: x['stability'])\n",
        "print(f\"\\nBest layer for steering: {best_layer['layer']} (stability={best_layer['stability']:.3f})\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zOb8VlkCPOGc"
      },
      "source": [
        "## 11. Interpretation Guide\n",
        "\n",
        "### Stability\n",
        "- **High (> 0.7)**: Contrastive pairs produce consistent directions - good steering vector\n",
        "- **Medium (0.4-0.7)**: Some consistency - may work but could be improved\n",
        "- **Low (< 0.4)**: Pairs produce inconsistent directions - need better contrastive pairs\n",
        "\n",
        "### Effect Size\n",
        "- **High**: Large separation between positive/negative - strong semantic difference\n",
        "- **Low**: Small separation - may need more distinct contrastive pairs\n",
        "\n",
        "### Layer Selection\n",
        "- Early layers: Often less consistent (low-level features)\n",
        "- Middle layers: Often best balance of consistency and effect\n",
        "- Late layers: May be too task-specific\n",
        "\n",
        "### Steering Scale\n",
        "- Too low: Minimal effect on generation\n",
        "- Too high: May degrade coherence\n",
        "- Sweet spot: Usually 1.0-3.0 (depends on model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1SdK1ykFPOGc"
      },
      "source": [
        "## 12. Quick Reference\n",
        "\n",
        "```python\n",
        "from shesha.bio import perturbation_stability, perturbation_effect_size\n",
        "\n",
        "# 1. Extract embeddings for contrastive pairs\n",
        "pos_hs = get_hidden_states(model, tokenizer, positive_prompts, layer_idx)\n",
        "neg_hs = get_hidden_states(model, tokenizer, negative_prompts, layer_idx)\n",
        "\n",
        "# 2. Compute steering vector\n",
        "steering_vector = pos_hs.mean(axis=0) - neg_hs.mean(axis=0)\n",
        "\n",
        "# 3. Check consistency with Shesha\n",
        "stability = perturbation_stability(neg_hs, pos_hs, seed=320)\n",
        "effect = perturbation_effect_size(neg_hs, pos_hs)\n",
        "\n",
        "if stability > 0.7:\n",
        "    print(\"Good steering vector!\")\n",
        "elif stability < 0.4:\n",
        "    print(\"Warning: Inconsistent - try different contrastive pairs\")\n",
        "\n",
        "# 4. Apply steering\n",
        "hook = SteeringHook(steering_vector, scale=2.0)\n",
        "hook.register(model, layer_idx)\n",
        "# ... generate ...\n",
        "hook.remove()\n",
        "```"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
